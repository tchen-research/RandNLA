{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Girard-Hutchinson Estimator\n",
    "\n",
    "Let $\\vec{x}$ be a random vector satisfying $\\mathbb{E}[\\vec{x}] = \\vec{0}$ and $\\mathbb{E}[\\vec{x}\\vec{x}^\\T] = \\vec{I}$.\n",
    "Then, a direct computations reveals that $\\vec{x}^\\T\\vec{A}\\vec{x}$ is an unbiased estimator of the trace of $\\vec{A}$. \n",
    "In particular, by the cylic property of the trace and linearity of expectation,\n",
    "\\begin{equation*}\n",
    "\\EE[ \\vec{x}^\\T \\vec{A}\\vec{x}] \n",
    "= \\EE[ \\tr(\\vec{x}^\\T \\vec{A}\\vec{x}) ] \n",
    "= \\EE[ \\tr(\\vec{A}\\vec{x}\\vec{x}^\\T ) ] \n",
    "= \\tr(\\vec{A}\\EE[ \\vec{x}\\vec{x}^\\T ] )\n",
    "= \\text{tr}(\\vec{A}).\n",
    "\\end{equation*}\n",
    "This suggests a simple randomized estimator.\n",
    "````{prf:definition} Girard-Hutchinson Estimator\n",
    ":label: def:girard_hutchinson_estimator\n",
    "Fix an integer $m \\geq 1$. The *Girard-Hutchinson trace estimator* is\n",
    "\\begin{equation*}\n",
    "\\widehat{\\tr}_m(\\vec{A}) := \\frac{1}{m}\\sum_{i=1}^{m} \\vec{x}_i^\\T \\vec{A} \\vec{x}_i,\n",
    "\\end{equation*}\n",
    "where $\\vec{x}_i$ are iid copies of some vector $\\vec{x}$ satisfying $\\mathbb{E}[\\vec{x}] = \\vec{0}$ and $\\mathbb{E}[\\vec{x}\\vec{x}^\\T] = \\vec{I}$.\n",
    "````\n",
    "A standard computation reveals that \n",
    "\\begin{equation*}\n",
    "\\EE[ \\widehat{\\tr}_m(\\vec{A}) ] = \\tr(\\vec{A}),\n",
    "\\qquad\n",
    "\\VV[ \\widehat{\\tr}_m(\\vec{A}) ] = \\frac{1}{m} \\VV[\\vec{x}^\\T\\vec{A}\\vec{x}].\n",
    "\\end{equation*}\n",
    "Thus, by increasing $m$, we can reduce the variance of the estimator to be arbitrarily small. \n",
    "\n",
    "Three common choices of $\\vec{x}$ are Gaussian, random unit vectors, and Rademacher random variables:\n",
    "- **Gaussian:** Each component of $\\vec{x}$ is iid $\\mathcal{N}(0,1)$.\n",
    "- **Random unit vector (real):** Each component of $\\vec{x}$ is iid $\\mathcal{N}(0,1)$, and then $\\vec{x}$ is normalized to have norm $\\sqrt{n}$.\n",
    "- **Rademacher:** Each component of $\\vec{x}$ is iid $\\{-1,1\\}$ with equal probability. \n",
    "\n",
    "When $\\vec{A}$ is symmetric, the variance of the estimator can be computed explicitly:\n",
    "| Distribution of $\\vec{x}$ | Variance:  $\\VV[\\vec{x}^\\T\\vec{A}\\vec{x}]$ |\n",
    "|-------|-----|\n",
    "| Gaussian     | $2 \\Vert\\vec{A}\\Vert_\\F^2$ |\n",
    "|  Rademacher  | $2 (\\Vert\\vec{A}\\Vert_\\F^2 - \\sum_i A_{ii}^2)$ |\n",
    "| Uniform (real)     | $\\frac{2n}{n+2} \\left( \\Vert \\vec{A} \\Vert_\\F^2 - \\frac{1}{n}\\tr(\\vec{A})^2 \\right)$ |\n",
    "\n",
    "If $\\vec{A}$ is not symmetric, we can use the fact that $\\widehat{\\tr}_m(\\vec{A})=\\widehat{\\tr}_m((\\vec{A} + \\vec{A}^\\T)/2)$.\n",
    "Readers can refer to Ethan's [blog post](https://www.ethanepperly.com/index.php/2023/01/26/stochastic-trace-estimation/) for a derivation of the variances listed above, as well as some additional discussion on interesting optimality properties of certain distributions.\n",
    "\n",
    "\n",
    "## A brief comment on history\n",
    "\n",
    "\n",
    "What we are calling a quadratic trace estimator is often called the *Hutchinson's trace estimator*, especially when $\\vec{x}$ is a random Rademacher vector\n",
    "However, {cite:p}`hutchinson_89` was not the first use of quadratic trace estimators for the task of approximating the trace of an implicit matrix; {cite:p}`hutchinson_89` itself cites {cite:p}`girard_87` which addresses the same task by using samples of \\( \\vec{v} \\) drawn uniformly from the unit hypersphere.\n",
    "Algorithms based on the use of random vectors back at least to the mid 1970s {cite:p}`alben_blume_krakauer_schwartz_75,weaire_williams_76,weaire_williams_77,deraedt_devries_89`.\n",
    "\n",
    "In fact, such estimators are a special case of the concept of *typicality* in quantum physics.\n",
    "\n",
    "\n",
    "Likewise, while the first tail bounds for quadratic trace estimators are typically attributed to {cite:p}`avron_toledo_11,roostakhorasani_ascher_14`, quadratic trace estimators were analyzed before either of these papers.\n",
    "For instance, {cite:p}`reimann_07` provides tail bounds based on Chebyshev's inequality for quadratic trace estimators used for the specific purpose of estimating the trace of a symmetric matrix.\n",
    "Sub-Gaussian concentration inequalities for quadratic trace estimators, similar to those in {cite:p}`avron_toledo_11,roostakhorasani_ascher_14` are derived in {cite:p}`popescu_short_winter_06` using Levy's Lemma, a general result about concentration of measure {cite:p}`ledoux_01`; see also {cite:t}`gogolin_10`.\n",
    "\n",
    "\n",
    "There are also many earlier analyses of quadratic trace estimators outside of the specific context of trace estimation.\n",
    "For instance, {cite:p}`hanson_wright_71` provides concentration bounds for quadratic trace estimators when the entries of $\\vec{x}$ are independent symmetric sub-Gaussian random variables. \n",
    "In fact, some of the strongest bounds for quadratic trace estimators {cite:p}`meyer_musco_musco_woodruff_21,persson_cortinovis_kressner_22` make use of so called *Hanson-Wright inequalities* {cite:p}`rudelson_vershynin_13` introduced in {cite:p}`hanson_wright_71`.\n",
    "Earlier still, {cite:p}`grenander_pollak_slepian_59` states as fact that the expectation of such estimators, when $\\vec{x}$ has iid Gaussian entries, is the sum of the eigenvalues of the matrix in question, citing a book {cite:p}`cramer_46` from the 1940s. \n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
