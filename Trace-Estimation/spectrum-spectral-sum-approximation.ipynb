{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Lanczos Quadrature\n",
    "\n",
    "Let $\\vec{A}\\in\\R^{n\\times n}$ be a symmetric matrix with eigendecomposition $\\vec{A} = \\sum_{i=1}^{n} \\lambda_i \\vec{u}_i \\vec{u}_i^\\T$, where $\\lambda_i$ are the eigenvalues and $\\vec{u}_i$ are the orthonormal eigenvectors of $\\vec{A}$.\n",
    "Matrix functions\n",
    "\\begin{equation*}\n",
    "f(\\vec{A}) := \\sum_{i=1}^{n} f(\\lambda_i) \\vec{u}_i \\vec{u}_i^\\T\n",
    "\\end{equation*}\n",
    "arise in a variety of applications.\n",
    "In many settings, we are interested in approximating the *spectral sum*\n",
    "\\begin{equation*}\n",
    "\\tr(f(\\vec{A})) = \\sum_{i=1}^{n} f(\\lambda_i).\n",
    "\\end{equation*}\n",
    "A natural approach is to combine the implicit trace estimation algorithms discussed earlier in this chapter with black-box methods for approximating $\\vec{x}\\mapsto \\vec{x}^\\T f(\\vec{A})\\vec{x}$ or $\\vec{x}\\mapsto f(\\vec{A})\\vec{x}$.\n",
    "\n",
    "\n",
    "## The Lanczos Method for Matrix Functions\n",
    "\n",
    "The Lanczos method can be used to approximate the maps $\\vec{x}\\mapsto \\vec{x}^\\T f(\\vec{A})\\vec{x}$ and $\\vec{x}\\mapsto f(\\vec{A})\\vec{x}$.\n",
    "\n",
    ":::{prf:definition} Krylov Subspace\n",
    "Given a matrix $\\vec{A}\\in\\R^{n\\times n}$ and a vector $\\vec{x}\\in\\R^n$, the *Krylov subspace* of order $k$ is defined as\n",
    "\\begin{equation*}\n",
    "\\mathcal{K}_k(\\vec{A}, \\vec{x}) := \\text{span}\\{\\vec{x}, \\vec{A}\\vec{x}, \\ldots, \\vec{A}^{k-1}\\vec{x}\\}.\n",
    "\\end{equation*}\n",
    ":::\n",
    "\n",
    "When applied to a symmetric matrix $\\vec{A}$ for $k$ iterations, the Lanczos method produces an orthonormal basis $\\vec{Q}\\in\\R^{n\\times k}$ for the Krylov subspace $\\mathcal{K}_k(\\vec{A}, \\vec{x})$ and a symmetric tridiagonal matrix $\\vec{T}\\in\\R^{k\\times k}$ such that $\\vec{T} = \\vec{Q}^\\T\\vec{A}\\vec{Q}$.\n",
    "The output of the Lanczos method can then be used to approximate $f(\\vec{A})\\vec{x}$ and $\\vec{x}^\\T f(\\vec{A})\\vec{x}$.\n",
    "This requires $k-1$ matrix-vector products with $\\vec{A}$.\n",
    "\n",
    ":::{prf:definition} Lanczos Method\n",
    "The Lanczos approximations to $f(\\vec{A})\\vec{x}$ and $\\vec{x}^\\T f(\\vec{A})\\vec{x}$ are respectively given by\n",
    "\\begin{equation*}\\begin{aligned}\n",
    "\\Call{Lan-FA}_k(f;\\vec{A},\\vec{x})&:= \\|\\vec{x}\\|\\vec{Q} f(\\vec{T})\\vec{e}_1 \\\\\n",
    "\\Call{Lan-QF}_k(f;\\vec{A},\\vec{x})&:=  \\|\\vec{x}\\|^2\\vec{e}_1^\\T f(\\vec{T})\\vec{e}_1.\n",
    "\\end{aligned}\\end{equation*}\n",
    ":::\n",
    "\n",
    "It is well-known that the accuracy of these approximations is related to how well $f(x)$ can be approximation by polynomials on the interval $[\\lambda_n,\\lambda_1]$.\n",
    "\n",
    ":::{prf:theorem} \n",
    ":label: thm:lanczos_FA\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "\\| f(\\vec{A})\\vec{x} - \\Call{Lan-FA}_k(f;\\vec{A},\\vec{x}) \\| &\\leq 2 \\|\\vec{x}\\| \\min_{\\deg(p)<k} \\left(\\max_{x\\in[\\lambda_n,\\lambda_1]} | f(x) - p(x) |\\right) \\\\\n",
    "| \\vec{x}^\\T f(\\vec{A})\\vec{x} - \\Call{Lan-QF}_k(f;\\vec{A},\\vec{x}) | &\\leq 2 \\|\\vec{x}\\|^2 \\min_{\\deg(p)<2k-1} \\left(\\max_{x\\in[\\lambda_n,\\lambda_1]} | f(x) - p(x) |\\right).\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    ":::\n",
    "\n",
    "In particular, note that when $f(x)$ is a low-degree polynomial, the approximations are exact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Stochastic Lanczos Quadrature\n",
    "\n",
    "Stochastic Lanczos Quadrature (SLQ) is the simple combination of the [Girard--Hutchinson estimator](./girard-hutchinson.ipynb) with the Lanczos method.\n",
    "\n",
    "````{prf:definition} Stochastic Lanczos Quadrature\n",
    "The *Stochastic Lanczos Quadrature* (SLQ) estimator for the spectral sum $\\tr(f(\\vec{A}))$ is given by\n",
    "\\begin{equation*}\n",
    "\\Call{SLQ}_{k,m}(f;\\vec{A}) := \\frac{1}{m} \\sum_{i=1}^{m} \\Call{Lan-QF}_k(f;\\vec{A},\\vec{x}_i),\n",
    "\\end{equation*}\n",
    "where $\\vec{x}_i$ are independent standard Gaussian vectors.\n",
    "````\n",
    "\n",
    "A simple application of the triangle inequality gives a bound on expected squared error of the SLQ estimator.\n",
    "\n",
    ":::{prf:theorem} \n",
    "\n",
    "For any $k,m\\geq 1$, the SLQ estimator uses $(k-1)m$ matrix-vector products to $\\vec{A}$ and satisfies\n",
    "\\begin{equation*}\n",
    "\\EE\\left[ | \\tr(f(\\vec{A})) - \\Call{SLQ}_{k,m}(f;\\vec{A}) |^2 \\right]\n",
    "\\leq \\frac{4\\| f(\\vec{A}) \\|_\\F^2}{m} + 6n^2  \\min_{\\deg(p)<2k-1} \\left( \\max_{x\\in[\\lambda_n,\\lambda_1]} | f(x) - p(x) | \\right).\n",
    "\\end{equation*}\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    ":::{admonition} Proof\n",
    ":class: dropdown \n",
    "\n",
    "By the triangle inequality and since $(x+y)^2\\leq 2(x^2+y^2)$, we have\n",
    "\\begin{equation*}\\begin{aligned}\n",
    "\\hspace{1em}&\\hspace{-1em}| \\tr(f(\\vec{A})) - \\Call{SLQ}_{k,m}(f;\\vec{A}) |^2\n",
    "\\\\&\\leq 2\\left| \\tr(f(\\vec{A})) - \\frac{1}{m}\\sum_{i=1}^{m} \\vec{x}_i^\\T f(\\vec{A})\\vec{x}_i \\right|^2 + 2\\left| \\frac{1}{m}\\sum_{i=1}^{m} \\vec{x}_i^\\T f(\\vec{A})\\vec{x}_i - \\Call{Lan-QF}_k(f;\\vec{A},\\vec{x}_i) \\right|^2.\n",
    "\\end{aligned}\\end{equation*}\n",
    "\n",
    "Note that \n",
    "\\begin{equation*}\n",
    "\\EE\\left[ \\left| \\tr(f(\\vec{A})) - \\frac{1}{m}\\sum_{i=1}^{m} \\vec{x}_i^\\T f(\\vec{A})\\vec{x}_i \\right|^2 \\right]\n",
    "= \n",
    "\\VV\\left[ \\widehat{\\tr}_m(f(\\vec{A})) \\right]\n",
    "= \\frac{2 \\| f(\\vec{A}) \\|_\\F^2}{m},\n",
    "\\end{equation*}\n",
    "where $\\widehat{\\tr}_m(\\cdot)$ is the [Girard--Hutchinson estimator](./girard-hutchinson.ipynb#def:girard_hutchinson_estimator).\n",
    "\n",
    "Next, by the triangle inequality and {prf:ref}`thm:lanczos_FA`, \n",
    "\\begin{equation*}\\begin{aligned}\n",
    "\\hspace{2em}&\\hspace{-2em}\n",
    "\\left| \\frac{1}{m}\\sum_{i=1}^{m} \\vec{x}_i^\\T f(\\vec{A})\\vec{x}_i - \\Call{Lan-QF}_k(f;\\vec{A},\\vec{x}_i) \\right|\n",
    "\\\\&\\leq \\frac{1}{m}\\sum_{i=1}^{m} \\left| \\vec{x}_i^\\T f(\\vec{A})\\vec{x}_i - \\Call{Lan-QF}_k(f;\\vec{A},\\vec{x}_i) \\right|\n",
    "\\\\&\\leq \\frac{1}{m} \\sum_{i=1}^{m} \\|\\vec{x}_i\\|^2 \\min_{\\deg(p)<2k-1} \\max_{x\\in[\\lambda_n,\\lambda_1]} | f(x) - p(x) |.\n",
    "\\end{aligned}\\end{equation*}\n",
    "Hence, \n",
    "\\begin{equation*}\\begin{aligned}\n",
    "\\hspace{2em}&\\hspace{-2em}\n",
    "\\EE\\left[ \\left| \\frac{1}{m}\\sum_{i=1}^{m} \\vec{x}_i^\\T f(\\vec{A})\\vec{x}_i - \\Call{Lan-QF}_k(f;\\vec{A},\\vec{x}_i) \\right|^2 \\right]\n",
    "\\\\&\\leq \\frac{1}{m^2}\\EE\\left[  \\left(\\sum_{i=1}^{m} \\|\\vec{x}_i\\|^2 \\right)^2 \\right] \\min_{\\deg(p)<2k-1} \\max_{x\\in[\\lambda_n,\\lambda_1]} | f(x) - p(x) |\n",
    "\\end{aligned}\\end{equation*}\n",
    "Now, note that $\\sum_{i=1}^{m} \\|\\vec{x}_i\\|^2$ is a Chi-squared random variable with $mn$ degrees of freedom. \n",
    "By looking on [Wikipedia](https://en.wikipedia.org/wiki/Chi-squared_distribution), we see that\n",
    "\\begin{equation*}\n",
    "\\EE\\left[  \\left(\\sum_{i=1}^{m} \\|\\vec{x}_i\\|^2 \\right)^2 \\right] = 2mn + (mn)^2 \\leq 3(mn)^2.\n",
    "\\end{equation*}\n",
    "Combining all of the above gives the result.\n",
    "\n",
    ":::\n",
    "\n",
    "Note that for \"nice\" functions $f(x)$, the error of the best polynomial approximation decreases exponentially with $k$ {cite:p}`trefethen_19`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Randomized Matrix Free Quadrature\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "````{prf:definition}\n",
    "\n",
    "The *spectral density* of $\\vec{A}$ is the probability measure \n",
    "```{math}\n",
    "\\varphi(x) := \\frac{1}{n} \\sum_{i=1}^{n} \\delta(x - \\lambda_i),\n",
    "```\n",
    "where $\\delta(x)$ is the Dirac delta at zero$.\n",
    "\n",
    "````\n",
    "\n",
    "We are interested approximating the spectral density of $\\vec{A}$, as well a \n",
    "\n",
    "Observe that \n",
    "```{math}\n",
    "\\tr(f(\\vec{A})) = n\\int_{-\\infty}^{\\infty} f(x) \\varphi(x) \\d{x},\n",
    "```\n",
    "Likewise,\n",
    "```{math}\n",
    "\\Phi(\\alpha) := n\\int_{-\\infty}^{\\alpha} \\varphi(x) \\d{x} = \\tr(f_\\alpha(\\vec{A})),\\quad f_\\alpha(x) = \\begin{cases}\n",
    "1 & \\text{if } x \\leq \\alpha,\\\\\n",
    "0 & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "```\n",
    "Hence approximating the spectral density and approximating spectral sums are equivalent.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
