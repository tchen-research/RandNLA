{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: One-pass (Nyström) methods\n",
    "description: Nyström methods for low-rank approximation of symmetric and positive semidefinite matrices\n",
    "keywords: [Nyström method, generalized Nyström, symmetric matrices, positive semidefinite, kernel matrices, column sampling, eigenvalue decomposition]\n",
    "numbering:\n",
    "  equation:\n",
    "    enumerator: 5.%s\n",
    "    continue: true\n",
    "  proof:theorem:\n",
    "    enumerator: 5.%s\n",
    "    continue: true\n",
    "  proof:algorithm:\n",
    "    enumerator: 5.%s\n",
    "    continue: true\n",
    "  proof:definition:\n",
    "    enumerator: 5.%s\n",
    "    continue: true\n",
    "  proof:proposition:\n",
    "    enumerator: 5.%s\n",
    "    continue: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The [Randomized SVD](alg-randomized-svd) (RSVD) and improvements require multiple passes over $\\vec{A}$.\n",
    "In some cases, it may be advantageous to use a method that only requires a single pass over $\\vec{A}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Nyström for positive definite matrices\n",
    "\n",
    "When $\\vec{A}$ is symmetric positive semi-definite, we can use the Nyström approximation generated by a sketching matrix $\\vec{\\Omega}\\in\\R^{n\\times k}$.\n",
    "```{math}\n",
    ":label: def-nystrom\n",
    "\\vec{A} \\langle \\vec{\\Omega}\\rangle := \\vec{A}\\vec{\\Omega} ( \\vec{\\Omega}^\\T\\vec{A}\\vec{\\Omega})^+ \\vec{\\Omega}^\\T\\vec{A}.\n",
    "```\n",
    "When $\\vec{\\Omega}$ is a Gaussian sketching matrix, this method satisfies similar theoretical guarantees to the Randomized SVD (with respect to $k$), despite requiring half the number of matrix-vector products and only one pass over the data; see e.g. Corollary 8.2 in {cite:p}`tropp_webber_23`.\n",
    "\n",
    "\n",
    "### Block Krylov methods\n",
    "\n",
    "In fact, at the cost of more passes over the data, we can replace $\\vec{\\Omega}$ with a basis for a Krylov subspace. \n",
    "As noted in Lemma 5.2 in {cite:p}`tropp_webber_23` (below), the Nyström method always produces a low-rank approximation that is at least as good one-sided projection based methods [Randomized Block Krylov Iteration](./subspace-iteration-block-krylov.ipynb).\n",
    "\n",
    "\n",
    ":::{prf:lemma} Nyström Helps\n",
    ":label: thm-nystrom-helps\n",
    "Consider a psd matrix $\\vec{A} \\in \\R^{n \\times n}$ and any matrix $\\vec{M} \\in \\R^{n \\times b}$. Then\n",
    "\\begin{equation*}\n",
    "\\|\\vec{A} - \\vec{A}\\langle\\vec{M}\\rangle\\|_p \\leq \\|\\vec{A} - \\vec{\\Pi}_{\\vec{M}} \\vec{A}\\|_p = \\|\\vec{A} - \\vec{A}\\vec{\\Pi}_{\\vec{M}}\\|_p\n",
    "\\end{equation*}\n",
    "for any Schatten $p$-norm with $1 \\leq p \\leq \\infty$. The same inequality holds for any unitarily invariant norm.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Generalized Nyström for arbitrary matrices\n",
    "\n",
    "A similar approach can be used for arbitrary $\\vec{A}$.\n",
    "Given sketching matrices $\\vec{\\Omega}\\in\\R^{d\\times k_1}$ and $\\vec{\\Psi}\\in\\R^{n\\times k_2}$, the Generalized Nyström approximation is the approximation\n",
    "```{math}\n",
    ":label: def-generalized-nystrom\n",
    "\\vec{A}\\langle \\vec{\\Omega},\\vec{\\Psi}\\rangle\n",
    ":= \\vec{A}\\vec{\\Omega} (\\vec{\\Psi}^\\T\\vec{A}\\vec{\\Omega})^+ \\vec{\\Psi}^\\T\\vec{A}.\n",
    "```\n",
    "\n",
    "We can understand the Generalized Nyström method as approximating the adaptive step in the Randomized SVD.\n",
    "Indeed, note that the matrix $\\vec{X} = \\vec{A}^\\T\\vec{Q}$ computed by the Randomized SVD is the matrix of coefficients for the linear combination of the columns of $\\vec{Q}$ that best approximates the columns of $\\vec{A}$. \n",
    "That is,\n",
    "```{math}\n",
    "\\vec{A}\\vec{Q}\n",
    "= \n",
    "\\argmin_{\\vec{X}\\in\\R^{b\\times d}} \\| \\vec{A} - \\vec{Q}\\vec{X}^\\T \\|_\\F.\n",
    "```\n",
    "Consider instead the [sketched regression](../04-Regression/sketch-and-solve.ipynb) problem\n",
    "```{math}\n",
    ":label: eq-nystrom-regression\n",
    "\\argmin_{\\vec{X}\\in\\R^{b\\times d}} \\| \\vec{\\Phi}^\\T \\vec{A} - \\vec{\\Phi}^\\T \\vec{Q}\\vec{X}^\\T \\|_\\F.\n",
    "```\n",
    "This results in an approximation\n",
    "```{math}\n",
    "\\vec{Q}\\vec{X}^\\T = \\vec{Q}(\\vec{\\Psi}^\\T\\vec{Q})^+ \\vec{\\Phi}^\\T \\vec{A}\n",
    "= \\vec{A}\\langle \\vec{\\Omega},\\vec{\\Psi}\\rangle.\n",
    "```\n",
    "\n",
    "The above procedure is summarized by the following algorithm.\n",
    ":::{prf:algorithm} Generalized Nyström\n",
    ":label: alg-generalized-nystrom\n",
    "\n",
    "**Input:** Matrix $A \\in \\R^{m \\times n}$, target rank $k$, block-sizes $b,c\\geq k$\n",
    "\n",
    "1. Sample a random sketching matrix $\\vec{\\Omega}\\sim\\Call{Sketch}(n,b)$\n",
    "1. Sample a random sketching matrix $\\vec{\\Psi}\\sim\\Call{Sketch}(d,c)$\n",
    "1. Compute $\\vec{Y} = \\vec{A} \\vec{\\Omega}$ and $\\vec{Z} = \\vec{A}^\\T \\vec{\\Psi}$\n",
    "1. Compute QR factorization $\\vec{Q}\\vec{R} = \\Call{qr}(\\vec{Y})$\n",
    "1. Compute $\\vec{X} = (\\vec{\\Psi}^\\T\\vec{Q})^+\\vec{Z}^\\T$\n",
    "\n",
    "**Output:** $\\vec{Q}\\vec{X}^\\T$\n",
    ":::\n",
    "\n",
    "\n",
    "### Sketching dimension\n",
    "\n",
    "To obtain a $(1+\\varepsilon)$ approximation in the Frobenius norm (similar to {prf:ref}`thm-rsvd-frob` for the RSVD), its not too hard to show that we must solve the regression problem {prf:ref}`eq-nystrom-regression` to relative accuracy $(1+\\varepsilon)$. \n",
    "Based on the analysis on [sketch-and-solve](../04-Regression/sketch-and-solve.ipynb), this requires that the sketching matrix $\\vec{\\Phi}$ have roughly $1/\\varepsilon$ times the number of columns as $\\vec{\\Phi}^\\T \\vec{Q}$.\n",
    "\n",
    "This is in contrast to the approximation {prf:ref}`def-nystrom` for positive semi-definite case, which works with the same sketching dimension as the Randomized SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
