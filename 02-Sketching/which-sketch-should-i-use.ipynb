{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Which Sketch Should I Use?\n",
    "description: Comparative analysis of different sketching methods including performance benchmarks and distortion measurements\n",
    "keywords: [sketch comparison, Gaussian sketch, trigonometric sketch, sparse sketch, performance benchmarks, distortion analysis]\n",
    "numbering:\n",
    "  equation:\n",
    "    enumerator: 2.%s\n",
    "    continue: true\n",
    "  proof:theorem:\n",
    "    enumerator: 2.%s\n",
    "    continue: true\n",
    "  proof:algorithm:\n",
    "    enumerator: 2.%s\n",
    "    continue: true\n",
    "  proof:definition:\n",
    "    enumerator: 2.%s\n",
    "    continue: true\n",
    "  proof:proposition:\n",
    "    enumerator: 2.%s\n",
    "    continue: true\n",
    "---\n",
    "\n",
    "*This section shares the title of Ethan's [blog post](https://www.ethanepperly.com/index.php/2023/11/27/which-sketch-should-i-use/), which inspired the design of the experiments we conduct here.*\n",
    "\n",
    "\n",
    "In the past several sections, we have seen several oblivious sketching methods. \n",
    "Which one should we use?\n",
    "\n",
    "In short, we recommend [Sparse Sketches](./sparse-sketch.md) as a good default choice. \n",
    "In settings where dense matrix-matrix multiplication is highly optimized (e.g. when working with relatively small matrices on GPUs), dense sketches may be preferable.\n",
    "\n",
    "## Comparison\n",
    "\n",
    "The following summarizes the performance of the different sketching methods we have seen so far.\n",
    "\n",
    "| Sketch Type | Embedding dimension $k$ | Apply Cost |\n",
    "|-------------|------------|------|\n",
    "| Gaussian Sketch | $O(d)$ | $O(\\nnz(\\vec{A}) k)$ |\n",
    "| Trigonometric Sketch | $O(d\\log(d))$ | $O(n d \\log (n))$ | \n",
    "| SparseStack | $O(d)$ | $O(\\nnz(\\vec{A}) \\log (d))$ |\n",
    "\n",
    "\n",
    "Theoretically, SparseStack sketches seem to be the best choice. \n",
    "They achieve an optimal embedding dimension $O(d)$ and are efficient to apply to both dense and sparse $\\vec{A}$.\n",
    "\n",
    "\n",
    "## Numerical Experiments\n",
    "\n",
    "We now perform some numerical comparisons which show that SparseStack sketches are a good choice in practice as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import fft,sparse\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from randnla import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Apply Cost\n",
    "\n",
    "We begin by comparing the cost of generating and applying the different sketches.\n",
    "When timing the apply time, we consider the time to apply the sketch matrix to a dense matrix $\\vec{A}$, as well as the time to apply the sketch matrix to a sparse matrix $\\vec{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2**14\n",
    "d = 200\n",
    "\n",
    "A = np.random.randn(n,d)\n",
    "A_s = sp.sparse.random(n,d, density=0.01).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1c39d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1c39d_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n",
       "      <th id=\"T_1c39d_level0_col1\" class=\"col_heading level0 col1\" >gen. time (s)</th>\n",
       "      <th id=\"T_1c39d_level0_col2\" class=\"col_heading level0 col2\" >apply to dense time (s)</th>\n",
       "      <th id=\"T_1c39d_level0_col3\" class=\"col_heading level0 col3\" >apply to sparse time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1c39d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1c39d_row0_col0\" class=\"data row0 col0\" >Gaussian</td>\n",
       "      <td id=\"T_1c39d_row0_col1\" class=\"data row0 col1\" >2.28e+00</td>\n",
       "      <td id=\"T_1c39d_row0_col2\" class=\"data row0 col2\" >3.73e-01</td>\n",
       "      <td id=\"T_1c39d_row0_col3\" class=\"data row0 col3\" >1.05e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c39d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1c39d_row1_col0\" class=\"data row1 col0\" >Trig</td>\n",
       "      <td id=\"T_1c39d_row1_col1\" class=\"data row1 col1\" >6.22e-03</td>\n",
       "      <td id=\"T_1c39d_row1_col2\" class=\"data row1 col2\" >1.54e-01</td>\n",
       "      <td id=\"T_1c39d_row1_col3\" class=\"data row1 col3\" >1.93e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c39d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1c39d_row2_col0\" class=\"data row2 col0\" >Sparse (zeta=4)</td>\n",
       "      <td id=\"T_1c39d_row2_col1\" class=\"data row2 col1\" >4.96e-03</td>\n",
       "      <td id=\"T_1c39d_row2_col2\" class=\"data row2 col2\" >2.82e-02</td>\n",
       "      <td id=\"T_1c39d_row2_col3\" class=\"data row2 col3\" >6.50e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c39d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1c39d_row3_col0\" class=\"data row3 col0\" >Sparse (zeta=8)</td>\n",
       "      <td id=\"T_1c39d_row3_col1\" class=\"data row3 col1\" >7.13e-03</td>\n",
       "      <td id=\"T_1c39d_row3_col2\" class=\"data row3 col2\" >4.84e-02</td>\n",
       "      <td id=\"T_1c39d_row3_col3\" class=\"data row3 col3\" >1.24e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b0c46d1cfa0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketch_methods = {\n",
    "    'Gaussian': {\n",
    "        'func': lambda k,rng: gaussian_sketch(n,k,rng),\n",
    "    },\n",
    "    'Trig': {\n",
    "        'func': lambda k,rng: trig_sketch(n,k,rng),\n",
    "    },\n",
    "    'Sparse (zeta=4)': {\n",
    "        'func': lambda k,rng: sparse_stack_sketch(n,k,4,rng),\n",
    "    },\n",
    "    'Sparse (zeta=8)': {\n",
    "        'func': lambda k,rng: sparse_stack_sketch(n,k,8,rng),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "k = 10*d\n",
    "\n",
    "n_repeat = 1\n",
    "\n",
    "results = []\n",
    "\n",
    "for method_name, method_info in sketch_methods.items():\n",
    "    # Time the method\n",
    "    start = time.time()\n",
    "    for i in range(n_repeat):\n",
    "        rng = np.random.RandomState(i)\n",
    "        S = method_info['func'](k,rng)\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_gen_time = (end - start) / n_repeat\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_repeat):\n",
    "        S@A\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_dense_apply_time = (end - start) / n_repeat \n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(n_repeat):\n",
    "        S@A_s\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_sparse_apply_time = (end - start) / n_repeat \n",
    "    \n",
    "    # Compute accuracy metrics\n",
    "    results.append({\n",
    "        'method': method_name,\n",
    "        'gen. time (s)': avg_gen_time,\n",
    "        'apply to dense time (s)': avg_dense_apply_time,\n",
    "        'apply to sparse time (s)': avg_sparse_apply_time,\n",
    "    })\n",
    "\n",
    "\n",
    "# Create DataFrame and compute relative performance\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results with formatting\n",
    "results_df.style.format({\n",
    "    'gen. time (s)': '{:1.2e}',\n",
    "    'apply to dense time (s)': '{:1.2e}',\n",
    "    'apply to sparse time (s)': '{:1.2e}'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the experiment are essentially as expected. \n",
    "We emphasize that SparseStack sketches are able to take advantage of sparsity in $\\vec{A}$, which is not the case for trig sketches.\n",
    "\n",
    "Note also that generating a Gaussian sketch is extremely expensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distortion\n",
    "\n",
    "We now consider the distortion of the different sketches for two different subspaces. \n",
    "The first subspace is a random subspace, which we generate by sampling a random orthonormal basis, and the second is a subspace spanned by the first $k$ columns of a random matrix $\\vec{A}$, which is known to be a hard example for sparse sketching distributions.\n",
    "We also plot $\\epsilon = \\sqrt{d/k}$, which is the asymptotic distortion for large Gaussian matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,_ = np.linalg.qr(A)\n",
    "\n",
    "U_hard = np.zeros((n,d))\n",
    "U_hard[:d] = np.eye(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Now run the experiment\n",
    "# ========================\n",
    "\n",
    "\n",
    "sketch_problems = {\n",
    "    'typical': {\n",
    "        'U': U,\n",
    "    },\n",
    "    'hard': {\n",
    "        'U': U_hard,\n",
    "    },\n",
    "}\n",
    "\n",
    "ks = np.geomspace(2*d,1000,5,dtype=int)\n",
    "\n",
    "n_repeat = 10\n",
    "\n",
    "results = {}\n",
    "\n",
    "for problem_name,problem_info in sketch_problems.items():\n",
    "\n",
    "    U_problem = problem_info['U']\n",
    "    for method_name, method_info in sketch_methods.items():\n",
    "\n",
    "\n",
    "        distortion = np.zeros((n_repeat,len(ks)))\n",
    "        for i in range(n_repeat):\n",
    "            rng = np.random.RandomState(i)\n",
    "            for j,k in enumerate(ks):\n",
    "            \n",
    "                S = method_info['func'](k,rng)\n",
    "                Y = S@U_problem\n",
    "\n",
    "                s = np.linalg.svd(Y,compute_uv=False)\n",
    "                distortion[i,j] = max(s[0]-1,1-s[-1]) \n",
    "\n",
    "        results[problem_name,method_name] = {\n",
    "            'distortion': distortion,\n",
    "        }\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Plot the results\n",
    "# ========================\n",
    "σ = 0.1\n",
    "fig, axs = plt.subplots(1,len(sketch_problems),figsize=(10, 4),sharey=True)\n",
    "\n",
    "# Handle case where we only have one subplot\n",
    "if len(sketch_problems) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "for i, (problem_name, problem_info) in enumerate(sketch_problems.items()):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    for method_name, method_info in sketch_methods.items():\n",
    "        # Get the distortion data for this problem and method\n",
    "        distortion = results[problem_name, method_name]['distortion']\n",
    "        \n",
    "        bot, mid, top = np.quantile(distortion, [σ, .5, 1-σ], axis=0)\n",
    "        ax.plot(ks/d, mid, label=method_name, linewidth=2)\n",
    "        ax.fill_between(ks/d, bot, top, alpha=.2)\n",
    "\n",
    "    # Theoretical bound\n",
    "    ax.plot(ks/d, np.sqrt(d/ks), ls=':', color='k', label=r'$\\sqrt{d/k}$ estimate')\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Sketch size ($k/d$)')\n",
    "    ax.set_title(f'Distortion vs Sketch Size - {problem_name.capitalize()} Problem')\n",
    "\n",
    "axs[0].set_ylabel(rf'Distortion $\\varepsilon$')\n",
    "axs[0].legend()\n",
    "\n",
    "plt.savefig('distortion.svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./distortion.svg)\n",
    "\n",
    "On the typical problem, all sketches perform remarkably similarly to the asymptotic Gaussian rate.\n",
    "Numerical experiments on a wide range of problems further confirm this observation {cite:p}`chen_niroula_ray_subrahmanya_pistoia_kumar_25,?`.\n",
    "However, on the hard problem, when the sparsity is too low, the performance of SparseStack sketches degrades slightly. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
