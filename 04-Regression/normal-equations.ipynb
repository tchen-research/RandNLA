{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\ntitle: Randomized Factorization-based Solvers\ndescription: Fast linear regression using randomized QR factorization and half preconditioned normal equations\nkeywords: [randomized Cholesky QR, half preconditioned normal equations, linear regression, factorization-based solvers, sketched QR]\nnumbering:\n  equations:\n    enumerator: 4.%s\n    continue: true\n  proof:theorem:\n    enumerator: 4.%s\n    continue: true\n  proof:algorithm:\n    enumerator: 4.%s\n    continue: true\n  proof:definition:\n    enumerator: 4.%s\n    continue: true\n  proof:proposition:\n    enumerator: 4.%s\n    continue: true\n---\n\nAs noted in the introduction to this chapter, the classical direct approach to solving  the {eq}`task-regression` problem is to first compute a factorization (e.g. QR, SVD) of $\\vec{A}$ in $O(nd^2)$ operations, and then use the factorization to solve the problem in $O(nd)$ operations.\nThe factorization step is typically the computational bottleneck, but the algorithms discussed in the previous chapter can be applied in a black-box manner. \n\n\n:::{prf:algorithm} Randomized Cholesky QR Regression\n:label: rand-chol-qr\n\n**Input:** $\\vec{A}\\in\\R^{n\\times d}$, $\\vec{b}\\in\\R^n$, sketching dimension $k$\n\n1. Get $\\vec{Q},\\vec{R} = \\Call{Randomized-Cholesky-QR}(\\vec{A},k)$\n1. Solve $\\vec{R}\\vec{x} = \\vec{Q}^\\T\\vec{b}$\n\n**Output:** $\\vec{x}$\n:::\n\n\n\nRecall, however, that the $\\vec{Q}$ factor produced by the randomized Cholesky QR algorithm is compute as $\\vec{Q} = \\vec{Q}_1 \\vec{R}_1^{-1}$, where $\\vec{R}_1$, where $\\vec{R}_1$ is the Cholesky factor of $\\vec{Q}_1^\\T\\vec{Q}_1$, and $\\vec{Q}_1$ is the approximate orthogonal basis produced by the [Sketched QR algorithm](../03-QR-Factorization/randomized-cholesky-qr.ipynb#sketched-qr).\nSince we only need to compute $\\vec{Q}^\\T\\vec{b}$, but not $\\vec{Q}$ itself, we can avoid forming forming the product $\\vec{Q}_1\\vec{R}_1^{-1}$ explicitly.\nThis results in the following implementation:\n\n:::{prf:algorithm} Randomized Half Preconditioned Normal Equations\n:label: rand-HPNE\n\n**Input:** $\\vec{A}\\in\\R^{n\\times d}$, $\\vec{b}\\in\\R^n$, sketching dimension $k$\n\n1. Get $\\vec{Q}_1,\\vec{R}_1 = \\Call{Sketched-QR}(\\vec{A},k)$\n1. Form $\\vec{X} = \\vec{Q}_1^\\T\\vec{Q}_1$\n1. Compute Choleksy factorization $\\vec{R} = \\Call{chol}(\\vec{X})$\n1. $\\vec{R} = \\vec{R}_2\\vec{R}_1$\n1. Solve $\\vec{R}_2^\\T\\vec{R}\\vec{x} = \\vec{Q}_1^\\T\\vec{b}$\n\n**Output:** $\\vec{x}$\n:::\n\nThe name *half preconditioned normal equations* is based on {cite:p}`ipsen_25`.\n\nWe can easily implement the algorithm in Numpy:"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_HPNE(A,b,k,zeta,rng):\n",
    "\n",
    "    Q1,R1 = sketched_qr(A,k,zeta,rng)\n",
    "    X = Q1.T@Q1\n",
    "    R2 = np.linalg.cholesky(X).T\n",
    "    R = R2@R1\n",
    "    y = sp.linalg.solve_triangular(R2.T,Q1.T@b,lower=True)\n",
    "    x = sp.linalg.solve_triangular(R,y,lower=False)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Example\n",
    "\n",
    "Let's compare the performance of the three approaches described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from randnla import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_47d1e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_47d1e_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n",
       "      <th id=\"T_47d1e_level0_col1\" class=\"col_heading level0 col1\" >time (s)</th>\n",
       "      <th id=\"T_47d1e_level0_col2\" class=\"col_heading level0 col2\" >speedup</th>\n",
       "      <th id=\"T_47d1e_level0_col3\" class=\"col_heading level0 col3\" >error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_47d1e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_47d1e_row0_col0\" class=\"data row0 col0\" >Numpy</td>\n",
       "      <td id=\"T_47d1e_row0_col1\" class=\"data row0 col1\" >0.0678</td>\n",
       "      <td id=\"T_47d1e_row0_col2\" class=\"data row0 col2\" >1.0x</td>\n",
       "      <td id=\"T_47d1e_row0_col3\" class=\"data row0 col3\" >4.3e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_47d1e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_47d1e_row1_col0\" class=\"data row1 col0\" >Randomized Cholesky QR</td>\n",
       "      <td id=\"T_47d1e_row1_col1\" class=\"data row1 col1\" >0.0520</td>\n",
       "      <td id=\"T_47d1e_row1_col2\" class=\"data row1 col2\" >0.8x</td>\n",
       "      <td id=\"T_47d1e_row1_col3\" class=\"data row1 col3\" >8.2e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_47d1e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_47d1e_row2_col0\" class=\"data row2 col0\" >Randomized HPNE</td>\n",
       "      <td id=\"T_47d1e_row2_col1\" class=\"data row2 col1\" >0.0421</td>\n",
       "      <td id=\"T_47d1e_row2_col2\" class=\"data row2 col2\" >0.6x</td>\n",
       "      <td id=\"T_47d1e_row2_col3\" class=\"data row2 col3\" >6.1e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7477801b37f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define randomized Cholesky QR regression algorithm\n",
    "def randomized_cholesky_QR_regression(A,b,k,zeta,rng):\n",
    "\n",
    "    Q,R = randomized_cholesky_QR(A,k,zeta,rng)\n",
    "    x = sp.linalg.solve_triangular(R,Q.T@b,lower=False)    \n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# Generate a random matrix with controlled condition number\n",
    "n = 5000\n",
    "d = 300\n",
    "\n",
    "U, s, Vt = np.linalg.svd(np.random.rand(n, d), full_matrices=False)\n",
    "s = np.geomspace(1e-4, 1, d)  # Controlled singular values for numerical stability\n",
    "A = U @ np.diag(s) @ Vt\n",
    "\n",
    "b_norm = 1\n",
    "residual_norm = .1\n",
    "\n",
    "v = np.random.randn(n)\n",
    "v_span = U @ (U.T @ v)\n",
    "v_perp = v - v_span\n",
    "v_span /= np.linalg.norm(v_span)\n",
    "v_perp /= np.linalg.norm(v_perp)\n",
    "\n",
    "b = v_span * np.sqrt(b_norm**2 - residual_norm**2) + v_perp * residual_norm\n",
    "\n",
    "x_true = Vt.T@np.diag(1/s)@U.T@b\n",
    "rng = np.random.default_rng(0) \n",
    "\n",
    "k = int(1.5*d)\n",
    "zeta = 4\n",
    "\n",
    "\n",
    "# Define QR factorization methods\n",
    "qr_methods = {\n",
    "    'Numpy': {\n",
    "        'func': lambda: np.linalg.lstsq(A, b, rcond=None)[0],\n",
    "    },\n",
    "    'Randomized Cholesky QR': {\n",
    "        'func': lambda: randomized_cholesky_QR_regression(A,b,k,zeta,rng),\n",
    "    },\n",
    "    'Randomized HPNE': {\n",
    "        'func': lambda: randomized_HPNE(A,b,k,zeta,rng),\n",
    "    },\n",
    "}\n",
    "# Time the QR factorization methods\n",
    "n_repeat = 10  # Number of repetitions for averaging\n",
    "\n",
    "results = []\n",
    "\n",
    "for method_name, method_info in qr_methods.items():\n",
    "    # Time the method\n",
    "    start = time.time()\n",
    "    for _ in range(n_repeat):\n",
    "        x = method_info['func']()\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_time = (end - start) / n_repeat\n",
    "    \n",
    "    # Compute accuracy metrics\n",
    "    results.append({\n",
    "        'method': method_name,\n",
    "        'time (s)': avg_time,\n",
    "        'error': np.linalg.norm(x_true - x)/np.linalg.norm(x_true),\n",
    "    })\n",
    "\n",
    "# Create DataFrame and compute relative performance\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['speedup'] = results_df['time (s)'] / results_df['time (s)'].max()\n",
    "\n",
    "# Display results with formatting\n",
    "results_df.reindex(columns=['method','time (s)','speedup','error']).style.format({\n",
    "    'time (s)': '{:.4f}',\n",
    "    'speedup': '{:.1f}x',\n",
    "    'error': '{:1.1e}',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are as expected. All methods get similar accuracy, but the randomized methods are faster due to offloading most of the computation to matrix-matrix multiplication. \n",
    "The optimized variant is slightly faster than the typical Randomized Cholesky QR-based method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}