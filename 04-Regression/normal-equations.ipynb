{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Factorization-based Solvers\n",
    "description: Fast linear regression using randomized QR factorization and half preconditioned normal equations\n",
    "keywords: [randomized Cholesky QR, half preconditioned normal equations, linear regression, factorization-based solvers, sketched QR]\n",
    "numbering:\n",
    "  equations:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:theorem:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:algorithm:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:definition:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:proposition:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "---\n",
    "\n",
    "As noted in the introduction to this chapter, the classical direct approach to solving  the {eq}`task-regression` problem is to first compute a factorization (e.g. QR, SVD) of $\\vec{A}$ in $O(nd^2)$ operations, and then use the factorization to solve the problem in $O(nd)$ operations.\n",
    "The factorization step is typically the computational bottleneck, but the algorithms discussed in the previous chapter can be applied in a black-box manner. \n",
    "\n",
    "\n",
    ":::{prf:algorithm} Randomized Cholesky QR Regression (na√Øve)\n",
    ":label: rand-chol-qr-simple\n",
    "\n",
    "**Input:** $\\vec{A}\\in\\R^{n\\times d}$, $\\vec{b}\\in\\R^n$, sketching dimension $k$\n",
    "\n",
    "1. Get $\\vec{Q},\\vec{R} = \\Call{Randomized-Cholesky-QR}(\\vec{A},k)$\n",
    "1. Solve $\\vec{R}\\vec{x} = \\vec{Q}^\\T\\vec{b}$\n",
    "\n",
    "**Output:** $\\vec{x}$\n",
    ":::\n",
    "\n",
    "\n",
    "Recall, however, that the $\\vec{Q}$ factor produced by the randomized Cholesky QR algorithm is compute as $\\vec{Q} = \\vec{Q}_1 \\vec{R}_1^{-1}$, where $\\vec{R}_1$, where $\\vec{R}_1$ is the Cholesky factor of $\\vec{Q}_1^\\T\\vec{Q}_1$, and $\\vec{Q}_1$ is the approximate orthogonal basis produced by the [Sketched QR algorithm](../03-QR-Factorization/randomized-cholesky-qr.ipynb#sketched-qr).\n",
    "Since we only need to compute $\\vec{Q}^\\T\\vec{b}$, but not $\\vec{Q}$ itself, we can avoid forming forming the product $\\vec{Q}_1\\vec{R}_1^{-1}$ explicitly.\n",
    "This results in the following implementation:[^ref]\n",
    "\n",
    "[^ref]: This implementation was communicated to me by Ethan Epperly. A similar implementation appears in {cite:p}`ipsen_25`.\n",
    "\n",
    ":::{prf:algorithm} Randomized Cholesky QR Regression\n",
    ":label: rand-chol-qr\n",
    "\n",
    "**Input:** $\\vec{A}\\in\\R^{n\\times d}$, $\\vec{b}\\in\\R^n$, sketching dimension $k$\n",
    "\n",
    "1. Get $\\vec{Q}_1,\\vec{R}_1 = \\Call{Sketched-QR}(\\vec{A},k)$\n",
    "1. Solve $\\vec{Q}_1^\\T\\vec{Q}_1\\vec{y} = \\vec{Q}_1^\\T\\vec{b}$ (e.g. using Cholesky)\n",
    "1. Solve $\\vec{R}_1\\vec{x} = \\vec{y}$\n",
    "\n",
    "**Output:** $\\vec{x}$\n",
    ":::\n",
    "\n",
    "We can easily implement these algorithms in Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_cholesky_QR_regression_naive(A,b,k,zeta,rng):\n",
    "\n",
    "    Q,R = randomized_cholesky_QR(A,k,zeta,rng)\n",
    "    x = sp.linalg.solve_triangular(R,Q.T@b,lower=False)    \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_cholesky_QR_regression(A,b,k,zeta,rng):\n",
    "\n",
    "    Q1,R1 = sketched_qr(A,k,zeta,rng)\n",
    "\n",
    "    y = sp.linalg.solve(Q1.T@Q1,Q1.T@b,assume_a='pos')\n",
    "    x = sp.linalg.solve_triangular(R1,y,lower=False)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Example\n",
    "\n",
    "Let's compare the performance of the three approaches described above, on a least squares problem where $\\|\\vec{b}\\|$ and $\\|\\vec{b} - \\vec{A}\\vec{x}^*\\|$ are prescribed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from randnla import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 300\n",
    "\n",
    "R1 = np.triu(np.random.randn(d,d))\n",
    "R2 = np.triu(np.random.randn(d,d))\n",
    "x = np.random.randn(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random matrix with controlled condition number\n",
    "n = 5000\n",
    "d = 300\n",
    "\n",
    "U,s,Vt = np.linalg.svd(np.random.rand(n,d),full_matrices=False)\n",
    "s = np.geomspace(1e-4,1,d) # define singular values\n",
    "A = U@np.diag(s)@Vt\n",
    "\n",
    "# define ||b|| and ||b-Ax*||\n",
    "b_norm = 1\n",
    "residual_norm = .1\n",
    "\n",
    "# construct right hand side\n",
    "v = np.random.randn(n)\n",
    "v_span = U@(U.T@v)\n",
    "v_perp = v-v_span\n",
    "v_span /= np.linalg.norm(v_span)\n",
    "v_perp /= np.linalg.norm(v_perp)\n",
    "\n",
    "b = v_span*np.sqrt(b_norm**2-residual_norm**2)+v_perp*residual_norm\n",
    "\n",
    "# construct true solution\n",
    "x_true = Vt.T@np.diag(1/s)@U.T@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(1.5*d)\n",
    "zeta = 4\n",
    "\n",
    "# Define regression factorization methods\n",
    "regression_methods = [\n",
    "    {'name': 'Numpy',\n",
    "     'func': lambda: np.linalg.lstsq(A, b, rcond=None)[0]},\n",
    "    {'name': 'Rand. Cholesky QR (naive)',\n",
    "     'func': lambda: randomized_cholesky_QR_regression_naive(A,b,k,zeta,rng)},\n",
    "    {'name': 'Rand. Cholesky QR',\n",
    "     'func': lambda: randomized_cholesky_QR_regression(A,b,k,zeta,rng)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ef8d0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ef8d0_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n",
       "      <th id=\"T_ef8d0_level0_col1\" class=\"col_heading level0 col1\" >time (s)</th>\n",
       "      <th id=\"T_ef8d0_level0_col2\" class=\"col_heading level0 col2\" >speedup</th>\n",
       "      <th id=\"T_ef8d0_level0_col3\" class=\"col_heading level0 col3\" >error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ef8d0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ef8d0_row0_col0\" class=\"data row0 col0\" >Numpy</td>\n",
       "      <td id=\"T_ef8d0_row0_col1\" class=\"data row0 col1\" >0.0734</td>\n",
       "      <td id=\"T_ef8d0_row0_col2\" class=\"data row0 col2\" >1.0x</td>\n",
       "      <td id=\"T_ef8d0_row0_col3\" class=\"data row0 col3\" >3.7e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef8d0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ef8d0_row1_col0\" class=\"data row1 col0\" >Rand. Cholesky QR (naive)</td>\n",
       "      <td id=\"T_ef8d0_row1_col1\" class=\"data row1 col1\" >0.0556</td>\n",
       "      <td id=\"T_ef8d0_row1_col2\" class=\"data row1 col2\" >1.3x</td>\n",
       "      <td id=\"T_ef8d0_row1_col3\" class=\"data row1 col3\" >5.9e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef8d0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ef8d0_row2_col0\" class=\"data row2 col0\" >Rand. Cholesky QR</td>\n",
       "      <td id=\"T_ef8d0_row2_col1\" class=\"data row2 col1\" >0.0403</td>\n",
       "      <td id=\"T_ef8d0_row2_col2\" class=\"data row2 col2\" >1.8x</td>\n",
       "      <td id=\"T_ef8d0_row2_col3\" class=\"data row2 col3\" >9.2e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef8d0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ef8d0_row3_col0\" class=\"data row3 col0\" >Rand. Cholesky QR HPNE</td>\n",
       "      <td id=\"T_ef8d0_row3_col1\" class=\"data row3 col1\" >0.0508</td>\n",
       "      <td id=\"T_ef8d0_row3_col2\" class=\"data row3 col2\" >1.4x</td>\n",
       "      <td id=\"T_ef8d0_row3_col3\" class=\"data row3 col3\" >2.9e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb070173d60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0) \n",
    "\n",
    "# Time the regression methods\n",
    "n_repeat = 20  # Number of repetitions for averaging\n",
    "\n",
    "results = []\n",
    "\n",
    "for regression_method in regression_methods:\n",
    "    method_name = regression_method['name']\n",
    "    \n",
    "    # Time the method\n",
    "    start = time.time()\n",
    "    for _ in range(n_repeat):\n",
    "        x = regression_method['func']()\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_time = (end - start) / n_repeat\n",
    "    \n",
    "    # Compute accuracy metrics\n",
    "    results.append({\n",
    "        'method': method_name,\n",
    "        'time (s)': avg_time,\n",
    "        'error': np.linalg.norm(x_true - x)/np.linalg.norm(x_true),\n",
    "    })\n",
    "\n",
    "# Create DataFrame and compute relative performance\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['speedup'] = results_df['time (s)'].max() / results_df['time (s)']\n",
    "\n",
    "# Display results with formatting\n",
    "results_df.reindex(columns=['method','time (s)','speedup','error']).style.format({\n",
    "    'time (s)': '{:.4f}',\n",
    "    'speedup': '{:.1f}x',\n",
    "    'error': '{:1.1e}',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are as expected. All methods get similar accuracy, but the randomized methods are faster due to offloading most of the computation to matrix-matrix multiplication. \n",
    "The optimized variant is slightly faster than the typical Randomized Cholesky QR-based method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
