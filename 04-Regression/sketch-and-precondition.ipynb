{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Sketch and Precondition\n",
    "description: High-accuracy linear regression using randomized sketching for preconditioning iterative methods\n",
    "keywords: [sketch and precondition, preconditioning, iterative methods, LSQR, condition number, sketched QR, convergence acceleration]\n",
    "numbering:\n",
    "  equation:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:theorem:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:algorithm:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:definition:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "  proof:proposition:\n",
    "    enumerator: 4.%s\n",
    "    continue: true\n",
    "---\n",
    "\n",
    "The sketch-and-precondition approach provides a powerful alternative to both direct factorization methods and the [sketch-and-solve](sketch-and-solve.ipynb) paradigm for solving {eq}`task-regression`.\n",
    "Unlike sketch-and-solve, which may sacrifice accuracy for speed, sketch-and-precondition maintains high accuracy while achieving significant computational speedups.\n",
    "\n",
    "The key insight behind sketch-and-precondition is to use a randomized sketch to construct a preconditioner that improves the conditioning the {eq}`task-regression`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Preconditioned Iterative Methods\n",
    "\n",
    "Given any invertivle matrix $\\vec{M}\\in\\R^{d\\times d}$ (called a *preconditioner*), solving {eq}`task-regression` is equivalent to solving\n",
    "```{math}\n",
    ":label: eqn-preconditioned-regression\n",
    "\\min_{\\vec{y}} \\|\\vec{A}\\vec{M}\\vec{y} - \\vec{b}\\|\n",
    ",\\quad\n",
    "\\vec{x} = \\vec{M}\\vec{y}.\n",
    "```\n",
    "The convergence of iterative methods applied to the preconditioned system depends on the condition number of the preconditioned matrix $\\vec{A}\\vec{M}$.\n",
    "\n",
    ":::{prf:theorem}\n",
    "\n",
    "Suppose LSQR is applied to {ref}`eqn-preconditioned-regression` for $t$ iterations to produce an approximate solution $\\widehat{\\vec{x}}_t$.\n",
    "Then, for some \n",
    "\\begin{equation*}\n",
    "t = O \\left( \\cond(\\vec{A}\\vec{M}) \\log \\left( \\frac{1}{\\varepsilon} \\right) \\right),\n",
    "\\end{equation*}\n",
    "it holds that\n",
    "\\begin{equation*}\n",
    "\\| \\vec{A}(\\vec{x}^* - \\widehat{\\vec{x}}_t) \\| \\leq \\varepsilon \\|\\vec{b} - \\vec{A}\\vec{x}^*\\|.\n",
    "\\end{equation*}\n",
    "This requires $t$ matrix-vector products with $\\vec{A}$, $\\vec{A}^\\T$, $\\vec{M}$ and $\\vec{M}^\\T$, in addition to $O(tn)$ flops.\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Preconditioning\n",
    "\n",
    "The basic sketch-and-precondition algorithm follows a two-stage approach: first construct a preconditioner using a randomized sketch, then solve the preconditioned system using an iterative method.\n",
    "\n",
    ":::{prf:algorithm} Sketch and Precondition\n",
    ":label: sketch-and-precondition\n",
    "\n",
    "**Input:** $\\vec{A}\\in\\R^{n\\times d}$, $\\vec{b}\\in\\R^n$, sketching dimension $k$, tolerance $\\varepsilon$\n",
    "\n",
    "1. Get $\\vec{Q}_1,\\vec{R}_1 = \\Call{Sketched-QR}(\\vec{A},k)$\n",
    "2. Form preconditioner $\\vec{M} = \\vec{R}^{-1}$\n",
    "3. Set $\\widehat{\\vec{x}} = \\Call{Iterative-Method}(\\vec{A},\\vec{b},\\vec{M})$\n",
    "\n",
    "**Output:** $\\vec{x}$\n",
    ":::\n",
    "\n",
    "Any version of [Sketched-QR algorithm](../03-QR-Factorization/randomized-cholesky-qr.ipynb) that produces subspace embedding can be used.\n",
    "\n",
    ":::{prf:theorem}\n",
    "\n",
    "Suppose $\\vec{A}$ is full-rank and the sketch $\\vec{S}$ used by the [Sketched-QR algorithm](../03-QR-Factorization/randomized-cholesky-qr.ipynb) is an $\\varepsilon$-subspace embedding for $\\vec{A}$.\n",
    "Then \n",
    "\\begin{equation*}\n",
    "\\cond(\\vec{A}\\vec{M}) \\leq  \\frac{1+\\varepsilon}{1-\\varepsilon}.\n",
    "\\end{equation*}\n",
    ":::\n",
    "\n",
    ":::{prf:proof}\n",
    ":class: dropdown\n",
    ":enumerated: false\n",
    "\n",
    "Recall $\\vec{A} = \\vec{Q}\\vec{R}$.\n",
    "By {eq}`sketched-qr-well-conditioned`,\n",
    "\\begin{equation*}\n",
    "\\cond(\\vec{A}\\vec{M}) = \\cond(\\vec{A}\\vec{R}^{-1}) = \\cond(\\vec{Q}) \\leq (1+\\varepsilon)/(1-\\varepsilon)\n",
    "\\end{equation*}\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
