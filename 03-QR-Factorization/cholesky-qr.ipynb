{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Cholesky QR\n",
    "description: High-performance QR factorization using Cholesky decomposition of the Gram matrix for improved computational efficiency\n",
    "keywords: [Cholesky QR, Gram matrix, matrix multiplication, numerical stability, condition number, QR factorization]\n",
    "numbering:\n",
    "  equation:\n",
    "    enumerator: 3.%s\n",
    "    continue: true\n",
    "  proof:theorem:\n",
    "    enumerator: 3.%s\n",
    "    continue: true\n",
    "  proof:algorithm:\n",
    "    enumerator: 3.%s\n",
    "    continue: true\n",
    "  proof:definition:\n",
    "    enumerator: 3.%s\n",
    "    continue: true\n",
    "  proof:proposition:\n",
    "    enumerator: 3.%s\n",
    "    continue: true\n",
    "---\n",
    "\n",
    "The main downside to classical QR algorithms is that they are sequential. As we have [seen](../01-Background/cost-of-numerical-linear-algebra.ipynb), we get a much higher flop rate with matrix-multiplication than with matrix factorization. \n",
    "We can use this to our advantage by computing a QR factorization using the Cholesky factorization of the Gram matrix $\\vec{A}^\\T\\vec{A}$.\n",
    "Such an approach \n",
    "\n",
    "\n",
    ":::{prf:algorithm} CholeskyQR\n",
    ":label: cholesky-qr\n",
    "\n",
    "**Input:** $\\vec{A}\\in\\R^{n\\times d}$\n",
    "\n",
    "1. Form $\\vec{X} = \\vec{A}^\\T\\vec{A}$\n",
    "1. Compute Cholesky factorization $\\vec{R} = \\Call{chol}(\\vec{X})$\n",
    "1. Form $\\vec{Q} = \\vec{A}\\vec{R}^{-1}$\n",
    "\n",
    "**Output:** $\\vec{Q}, \\vec{R}$\n",
    ":::\n",
    "\n",
    "This algorithm is easily implemented in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_QR(A):\n",
    "\n",
    "    X = A.T@A\n",
    "    R = np.linalg.cholesky(X).T\n",
    "    Q = sp.linalg.solve_triangular(R.T,A.T,lower=True).T\n",
    "\n",
    "    return Q,R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost of [](#cholesky-qr) is dominated by the matrix-matrix product in the first line, which costs $O(nd^2)$ operations. \n",
    "Thus, we might hope that this algorithm runs faster in practice than standard QR factorization algorithms, since matrix-matrix multiplication has a very high flop-rate.\n",
    "In addition, [](#cholesky-qr) is mathematically exact; i.e. in exact arithmetic, it will produce a true QR factorization.\n",
    "\n",
    ":::{prf:theorem}\n",
    "The output of [](#cholesky-qr) is a QR factorization of $\\vec{A}$, i.e., $\\vec{A} = \\vec{Q}\\vec{R}$ where $\\vec{Q}$ has orthonormal columns and $\\vec{R}$ is upper triangular.\n",
    ":::\n",
    "\n",
    ":::{prf:proof}\n",
    ":class: dropdown\n",
    ":enumerated: false\n",
    "\n",
    "By construction $\\vec{R}$ is upper triangular and $\\vec{A} = \\vec{Q}\\vec{R}$.\n",
    "Since $\\vec{R}$ is the Cholesky factorization of $\\vec{A}^\\T\\vec{A}$, we have that $\\vec{R}^\\T\\vec{R} = \\vec{A}^\\T\\vec{A}$.\n",
    "This means that \n",
    "\\begin{equation*}\n",
    "\\vec{Q}^\\T \\vec{Q} = \\vec{R}^{-\\T}\\vec{A}^\\T\\vec{A}\\vec{R}^{-1} = \\vec{R}^{-\\T}\\vec{R}^\\T\\vec{R}\\vec{R}^{-1} = \\vec{I},\n",
    "\\end{equation*}\n",
    " so $\\vec{Q}$ is orthogonal.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Numerical Experiment\n",
    "\n",
    "Let's try to understand the performance of Cholesky QR relative to the default QR factorization method in Numpy.\n",
    "In addition to the runtime, we will compute the orthogonality and reconstruction errors \n",
    "```{math}\n",
    "\\|\\vec{Q}^\\T\\vec{Q} - \\vec{I}\\|\n",
    "\\quad\\text{and}\\quad\n",
    "\\|\\vec{A} - \\vec{Q}\\vec{R}\\|,\n",
    "```\n",
    "which are both zero for a perfect QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from randnla import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random matrix with controlled condition number\n",
    "n = 5000\n",
    "d = 300\n",
    "\n",
    "U,s,Vt = np.linalg.svd(np.random.rand(n,d),full_matrices=False)\n",
    "s = np.geomspace(1e-4,1,d) # define singular values\n",
    "A = U@np.diag(s)@Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define QR factorization methods\n",
    "qr_methods = [\n",
    "    {'name':'Householder QR',\n",
    "     'func': lambda: np.linalg.qr(A,mode='reduced')},\n",
    "    {'name':'Cholesky QR',\n",
    "     'func': lambda: cholesky_QR(A)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bef17\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bef17_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n",
       "      <th id=\"T_bef17_level0_col1\" class=\"col_heading level0 col1\" >time (s)</th>\n",
       "      <th id=\"T_bef17_level0_col2\" class=\"col_heading level0 col2\" >speedup</th>\n",
       "      <th id=\"T_bef17_level0_col3\" class=\"col_heading level0 col3\" >orthogonality</th>\n",
       "      <th id=\"T_bef17_level0_col4\" class=\"col_heading level0 col4\" >reconstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bef17_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bef17_row0_col0\" class=\"data row0 col0\" >Householder QR</td>\n",
       "      <td id=\"T_bef17_row0_col1\" class=\"data row0 col1\" >0.0909</td>\n",
       "      <td id=\"T_bef17_row0_col2\" class=\"data row0 col2\" >1.0x</td>\n",
       "      <td id=\"T_bef17_row0_col3\" class=\"data row0 col3\" >7.0e-15</td>\n",
       "      <td id=\"T_bef17_row0_col4\" class=\"data row0 col4\" >3.0e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bef17_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bef17_row1_col0\" class=\"data row1 col0\" >Cholesky QR</td>\n",
       "      <td id=\"T_bef17_row1_col1\" class=\"data row1 col1\" >0.0319</td>\n",
       "      <td id=\"T_bef17_row1_col2\" class=\"data row1 col2\" >2.8x</td>\n",
       "      <td id=\"T_bef17_row1_col3\" class=\"data row1 col3\" >4.3e-09</td>\n",
       "      <td id=\"T_bef17_row1_col4\" class=\"data row1 col4\" >6.7e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7be9a0b2dcf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time the QR factorization methods\n",
    "n_repeat = 10  # Number of repetitions for averaging\n",
    "\n",
    "results = []\n",
    "\n",
    "for qr_method in qr_methods:\n",
    "\n",
    "    method_name = qr_method['name']\n",
    "\n",
    "    # Time the method\n",
    "    start = time.time()\n",
    "    for _ in range(n_repeat):\n",
    "        Q, R = qr_method['func']()\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_time = (end - start) / n_repeat\n",
    "    \n",
    "    # Compute accuracy metrics\n",
    "    results.append({\n",
    "        'method': method_name,\n",
    "        'time (s)': avg_time,\n",
    "        'orthogonality': np.linalg.norm(Q.T @ Q - np.eye(d)),\n",
    "        'reconstruction': np.linalg.norm(A - Q @ R)\n",
    "    })\n",
    "\n",
    "# Create DataFrame and compute relative performance\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['speedup'] = results_df['time (s)'].max() / results_df['time (s)']\n",
    "\n",
    "# Display results with formatting\n",
    "results_df.reindex(columns=['method','time (s)','speedup','orthogonality','reconstruction']).style.format({\n",
    "    'time (s)': '{:.4f}',\n",
    "    'speedup': '{:.1f}x',\n",
    "    'orthogonality': '{:1.1e}',\n",
    "    'reconstruction': '{:1.1e}',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Cholesky QR is much faster than the standard Householder QR factorization.\n",
    "\n",
    "## Too good to be true?\n",
    "\n",
    "While CholeskyQR is faster than a standard QR method, our numerical experiment reveals that the $\\vec{Q}$ matrix produced by Cholesky SQR is much less orthogonal!\n",
    "The numerical instability can be traced back to presence of the Gram matrix $\\vec{A}^\\T\\vec{A}$. \n",
    "Indeed, $\\cond(\\vec{A}^\\T\\vec{A}) = \\cond(\\vec{A})^2$, so by forming the Gram matrix we end up making the conditioning way worse ðŸ’”.\n",
    "\n",
    "In the next section, we will explore how RandNLA can be used to produce a more accurate approximation, *while maintaining the efficiency of Cholesky QR*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
