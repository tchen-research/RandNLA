{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketching\n",
    "\n",
    "The workhorse of RandNLA is a technique called *sketching*. \n",
    "Sketching, broadly speaking, is a way to take a large matrix and create a smaller matrix (called a sketch) that approximates key properties of the original matrix.[^sketch]\n",
    "In RandNLA, sketching is almost always done using a linear transform of the original matrix.\n",
    "\n",
    "![](./sketch_def.svg)\n",
    "\n",
    "\n",
    "[^sketch]: This is like how a sketch captures the essence of an original image without all the details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oblivious embeddings\n",
    "\n",
    "Clearly we can obtain a subspace embedding with zero distortion by setting $\\vec{S}^\\T$ as an orthonormal basis for $V$.\n",
    "Of course, this is costly, and almost all relevant linear algebra tasks can be solved just as efficiently as we can obtain such a basis.\n",
    "Remarkably, for any fixed subspace, there are many ways to obtain a matrix that, with high probability, is a subspace embedding *without knowing anything about the subspace*.\n",
    "Such a subspace embedding is called an *oblivious subspace embedding*.\n",
    "\n",
    "### Gaussian matrices\n",
    "\n",
    "Gaussian matrices are the prototypical oblivious subspace embedding. \n",
    "Since Gaussian matrices have many nice mathematical properties, it is often easiest to analyze RandNLA algorithms which involve Gaussian matrices.\n",
    "However, generating and applying Gaussian matrices can be computationally expensive, requiring $O(nk)$ and $O(ndk)$ operations respectively.\n",
    "\n",
    "\n",
    " so other oblivious subspace embeddings have been developed that are more efficient in practice.\n",
    "We discuss some of these distributions [below](other-distributions).\n",
    "\n",
    "### Sparse sign matrices\n",
    "\n",
    "\n",
    "### Trigonometric matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling based embeddings\n",
    "\n",
    "TODO: decide on whether we want to treat sampling methods in parallel or on their own.\n",
    "Originally I aws thinking on their own, but now I'm leaning towards in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
