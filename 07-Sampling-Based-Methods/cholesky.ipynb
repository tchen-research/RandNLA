{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Randomly Pivoted Cholesky\n",
    "description: Randomized pivoting strategies and sampling approaches for Cholesky decomposition\n",
    "keywords: [Cholesky decomposition, randomized pivoting, sampling-based factorization, symmetric positive definite, pivot selection, numerical stability]\n",
    "numbering:\n",
    "  equation:\n",
    "    enumerator: 7.%s\n",
    "    continue: true\n",
    "  proof:theorem:\n",
    "    enumerator: 7.%s\n",
    "    continue: true\n",
    "  proof:algorithm:\n",
    "    enumerator: 7.%s\n",
    "    continue: true\n",
    "  proof:definition:\n",
    "    enumerator: 7.%s\n",
    "    continue: true\n",
    "  proof:proposition:\n",
    "    enumerator: 7.%s\n",
    "    continue: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $\\vec{A}$ is positive definite and recall the Nyström approximation\n",
    "```{math}\n",
    "\\vec{A} \\langle \\vec{\\Omega}\\rangle := \\vec{A}\\vec{\\Omega} ( \\vec{\\Omega}^\\T\\vec{A}\\vec{\\Omega})^+ \\vec{\\Omega}^\\T\\vec{A}.\n",
    "```\n",
    "When the columns of $\\vec{\\Omega}$ a subset of the columns of the identity, then $\\vec{A}\\vec{\\Omega}$ corresponds to subsampling the columns of $\\vec{A}$.\n",
    "In particular, let $S \\subseteq \\{1, \\ldots, n\\}$ be a tuple containing the $k$ *pivots* (columns of $\\vec{A}$) we will observe; i.e. so that $\\vec{\\Omega} = \\vec{I}[:,S]$.\n",
    "Then \n",
    "```{math}\n",
    ":label: def-nystrom-pivot\n",
    "\\vec{A} \\langle \\vec{\\Omega}\\rangle = \\vec{A}[:,S] \\vec{A}[S,S]^+ \\vec{A}[S,:] = : \\vec{A} \\langle S\\rangle.\n",
    "```\n",
    "In particular, since $\\vec{A}$ is symmetric, we can compute $\\vec{A} \\langle \\vec{\\Omega}\\rangle$ having only observed $\\vec{A}(:,S)$, which contains just $kn$ entries of $\\vec{A}$.\n",
    "\n",
    "The key question is how best to choose the columns of $\\vec{A}$. \n",
    "Ideally, we would like to choose $k$ columns so that the Nyström approximation is competitive with the best rank-$k$ approximation to $\\vec{A}$. \n",
    "\n",
    "\n",
    "## Partial Cholesky factorization with pivoting\n",
    "\n",
    "\n",
    "It turns out that, to compute {prf:ref}`def-nystrom-pivot` we can use a Cholesky factorization algorithm with pivoting, and stop after $k$ steps.\n",
    "\n",
    ":::{prf:algorithm} partial Cholesky factorization with pivoting\n",
    ":label: alg-partial-cholesky\n",
    "**Input:** $\\vec{A}\\in\\R^{n\\times n}$, pivots $S = (s_1, \\ldots, s_k)$\n",
    "\n",
    "1. Initialize $\\vec{F}_0 = []\\in\\R^{n\\times 0}$.\n",
    "1. For $i=1,\\ldots, k$\n",
    "    - $\\tilde{\\vec{g}}_i = \\vec{A}[:,s_i] - \\vec{F}_{i-1}\\vec{F}_{i-1}[s_i,:]^\\T$\n",
    "    - $ \\vec{g}_i = \\tilde{\\vec{g}}_i / \\sqrt{\\tilde{\\vec{g}}_i[s_i]}$\n",
    "    - $\\vec{F}_i = [\\vec{F}_{i-1} ~ \\vec{g}_i  ] \\in \\R^{n\\times i}$\n",
    "\n",
    "**Output:** $\\vec{F}_k\\vec{F}_k^\\T$\n",
    ":::\n",
    "\n",
    "\n",
    "Note that the \"textbook\" Cholesky factorization algorithms maintain $\\vec{A} - \\vec{F}_i \\vec{F}_i^\\T$ directly.\n",
    "On the other hand, anticipating that we will terminate for some $k<n$,  {prf:ref}`alg-partial-cholesky` only computes the necessary parts of $\\vec{A} - \\vec{F}_i\\vec{F}_i^\\T$ as they are needed.\n",
    "\n",
    "\n",
    ":::{prf:theorem}\n",
    "The output $\\vec{F}_k\\vec{F}_k^\\T$ of {prf:ref}`alg-partial-cholesky` with pivots $S$ is equal to $\\vec{A} \\langle S\\rangle$.\n",
    ":::\n",
    "\n",
    "\n",
    ":::{prf:proof}\n",
    ":class: dropdown\n",
    ":enumerated: false\n",
    "\n",
    "See Ethan's [blog](./https://www.ethanepperly.com/index.php/2022/10/24/nystrom-cholesky-and-schur/).\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Adaptive pivoting\n",
    "\n",
    "\n",
    "Nothing in {prf:ref}`alg-partial-cholesky` requires that the pivot $s_i$ be chosen prior to step $i$!\n",
    "In particular, we can choose the $i$-th pivot adaptively, based on the approximation $\\vec{A}\\langle S_{i-1}\\rangle = \\vec{F}_{i-1}\\vec{F}_{i-1}^\\T$, where $S_i := (s_1, \\ldots, s_{i-1})$.\n",
    "While computing the error $\\vec{A} - \\vec{A}\\langle S_{i-1}\\rangle $ would let us try to find the column that would reduce the error the most, we want to avoid looking at all of the entires of $\\vec{A}$.\n",
    "\n",
    "\n",
    "Amazingly, we can find good pivots without observing all of $\\vec{A}$.\n",
    "Towards this end, note that:\n",
    "1. The error $\\vec{A} - \\vec{A}\\langle \\vec{\\Omega} \\rangle$ of a Nyström approximation is positive definite.\n",
    "1. For any positive definite $\\vec{E}$, $\\|\\vec{E}\\|\\leq \\|\\vec{E}\\|_\\F \\leq \\tr(\\vec{E})$.\n",
    "\n",
    "By computing the $n$ diagonal entries of $\\vec{A}$, we can keep track of $\\operatorname{diag}(\\vec{A} - \\vec{A}\\langle S_{i-1}\\rangle )$ and use this to choose the pivot. \n",
    "One approach is to greedily choose the pivot as the largest entries of $\\operatorname{diag}(\\vec{A} - \\vec{A}\\langle S_{i-1}\\rangle )$.\n",
    "However, this approach is has the tendency to focus on outlier entires. \n",
    "Instead, we can sample proprtional to the values $\\operatorname{diag}(\\vec{A} - \\vec{A}\\langle S_{i-1}\\rangle )$.\n",
    "This results in the *Randomly Pivoted Cholesky* algorithm introduced in {cite:p}`chen_epperly_tropp_webber_25`\n",
    "\n",
    "\n",
    ":::{prf:algorithm} Randomly pivoted Cholesky\n",
    ":label: alg-rp-cholesky\n",
    "**Input:** $\\vec{A}\\in\\R^{n\\times n}$\n",
    "\n",
    "1. Initialize $\\vec{F}_0 = []\\in\\R^{n\\times 0}$, $\\vec{d}_0 = \\operatorname{diag}(\\vec{A})$\n",
    "1. For $i=1,\\ldots, k$\n",
    "    - Sample $s_i$ so that $\\PP[s_i = j] \\propto \\vec{d}_{i-1}[j]$\n",
    "    - $\\tilde{\\vec{g}}_i = \\vec{A}[:,s_i] - \\vec{F}_{i-1}\\vec{F}_{i-1}[s_i,:]^\\T$\n",
    "    - $ \\vec{g}_i = \\tilde{\\vec{g}}_i / \\sqrt{\\tilde{\\vec{g}}_i[s_i]}$\n",
    "    - $\\vec{F}_i = [\\vec{F}_{i-1} ~ \\vec{g}_i  ] \\in \\R^{n\\times i}$\n",
    "    - $\\vec{d}_i = \\vec{d}_{i-1} - \\operatorname{diag}(\\vec{g}_i\\vec{g}_{i}^\\T)$\n",
    "\n",
    "**Output:** $\\vec{F}_k\\vec{F}_k^\\T$\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
